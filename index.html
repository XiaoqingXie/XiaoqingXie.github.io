<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Xiaoqing Xie</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url(/assets/myphoto.png)">
        </div>
    </section>
    <section class='menu'>
        <div>Xiaoqing Xie</div>
        
        <ul>
          
            <a href="/Resume/" class="Btn">
              <li>Resume</li>
            </a>  
          
            <a href="/" class="Btn">
              <li>Blogs</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
            <a href="/tags/" class="Btn">
              <li>Tags</li>
            </a>  
          
            <a href="/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/about/" class="Btn">
              <li>About</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a target="_blank" rel="noopener" href="https://github.com/XiaoqingXie">
                    <img src="/assets/github.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Tensorflow/">学习笔记-Tensorflow</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-19T08:25:22.000Z" itemprop="datePublished">
    2022-07-19
  </time>
  
  
</div>

    </header>
    <div>
      
        
      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Pytorch/">学习笔记-Pytorch</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-19T08:25:10.000Z" itemprop="datePublished">
    2022-07-19
  </time>
  
  
</div>

    </header>
    <div>
      
        <p><strong>Pytorch vs Tensorflow</strong><br>Pytorch:简洁、动态计算、visdom、部署不方便<br>Tensorflow: 接口复杂、静态图(TF2.0 Eager Execution已经引入动态图)、Tensorboard、部署方便(TF serving)</p>
<p><strong>Pytorch安装与环境搭建</strong><br>Ubuntu16.04–CUDA+cuDNN–Python3+pip3/Anaconda–Pytorch<br>硬件要求：GTX1080Ti+16G内存</p>
<p><strong>Pytorch的基本概念</strong></p>
<ol>
<li>Tensor 张量<br>&emsp;使用Tensor对样本进行描述<br>&emsp;使用Tensor对模型中的变量进行描述<br>&emsp;Tensor的创建<br>&emsp;Tensor(*size)    基础构造函数<br>&emsp;Tensor(data)    类似np.array<br>&emsp;标量是零维的张量，向量是一维的张量，矩阵是二维的张量。</li>
</ol>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Hadoop/">学习笔记-Hadoop</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-18T08:26:44.000Z" itemprop="datePublished">
    2022-07-18
  </time>
  
  
</div>

    </header>
    <div>
      
        
      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Flink/">学习笔记-Flink</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-18T08:26:32.000Z" itemprop="datePublished">
    2022-07-18
  </time>
  
  
</div>

    </header>
    <div>
      
        <p><a target="_blank" rel="noopener" href="https://flink.apache.org/">Flink官网</a></p>
<p>学习Flink之前先了解两个概念：无界流和有界流<br>任何类型的数据都是作为事件流产生的。信用卡交易，传感器测量，机器日志或网站/移动应用程序上的用户交互，所有这些数据都作为流生成。<br>数据可以作为无界或有界流处理。<br><strong>无界流</strong>：有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取event，以便能够推断结果完整性。<br><strong>有界流</strong>：有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。</p>
<p><strong>Flink简介</strong><br>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据进行有状态计算。Flink设计为在所有常见的集群环境中进行，以内存速度和任何规模执行计算。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Spark/">学习笔记-Spark</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-18T08:26:20.000Z" itemprop="datePublished">
    2022-07-18
  </time>
  
  
</div>

    </header>
    <div>
      
        
      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/13/Linux-awk%E5%91%BD%E4%BB%A4/">Linux-awk命令</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-13T09:28:05.000Z" itemprop="datePublished">
    2022-07-13
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/Linux/">Linux</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <p>awk是一个强大的文本分析工具，可以对文本进行分析并生成报告。</p>
<p>工作原理：逐行读取文本，默认以空格或tab键为分隔符进行分隔，将分隔所得的各个字段保存到内建变量中，并按模式或者田间执行编辑命令。</p>
<p>sed命令常用于一整行的处理，而awk比较倾向于将一行分成多个“字段”然后再进行处理。awk信息的读入也是逐行读取的，执行结果可以通过print的功能将字段数据打印显示。在使用awk命令的过程中,可以使用逻辑操作符“&amp;&amp;”表示“与”、“||”表示“或”、“!”表示“非”；还可以进行简单的数学运算，如+、-、*、/、%、^分别表示加、减、乘、除、取余和乘方。</p>
<p>awk常见的内建变量（可直接用）如下所示<br>FS：列分割符。指定每行文本的字段分隔符，默认为空格或制表位。与”-F”作用相同<br>NF：当前处理的行的字段个数。<br>NR：当前处理的行的行号（序数）。<br>$0：当前处理的行的整行内容。<br>$n：当前处理行的第n个字段（第n列）。<br>FILENAME：被处理的文件名。<br>RS：行分隔符。awk从文件上读取资料时,将根据RS的定义把资料切割成许多条记录,而awk一次仅读入一条记录,以进行处理。预设值是’\n’</p>
<p>使用示例：<br>awk ‘{print}’ 1.txt        #输出所有内容<br>awk ‘{print $0}’ 1.txt        #输出所有内容<br>awk ‘NR==1,NR==3{print}’ 1.txt        #输出第1至3 行内容<br>awk ‘(NR&gt;=1)&amp;&amp;(NR&lt;=3){print}’ 1.txt        #输出第 1至3 行内容<br>awk ‘NR==1||NR==3{print}’ testfile2        #输出第1行、第3行内容<br>awk ‘(NR%2)==1{print}’ testfile2        #输出所有奇数行的内容<br>awk ‘(NR%2)==0{print}’ testfile2        #输出所有偶数行的内容<br>awk ‘/^root/{print}’ /etc/passwd        #输出以 root 开头的行<br>awk ‘/nologin$/{print}’ /etc/passwd        #输出以 nologin 结尾的行<br>awk -F “:” ‘{print NR,$0}’ /etc/passwd        #输出每行内容和行号，每处理完一条记录，NR值加1<br>awk -F “:” ‘$7~“/bash”{print $1}’ /etc/passwd        #输出以冒号分隔且第7个字段中包含/bash的行的第1个字段<br>awk -F “:” ‘($1~“root”)&amp;&amp;(NF==7){print $1,$2}’ /etc/passwd        #输出第1个字段中包含root且有7个字段的行的第1、2个字段<br>awk -F ‘\t’ ‘FILENAME~/predict/{if($2!=”NULL”)cid[$2]=$1}FILENAME~/label/{if($1 in cid)print cid[$1], $0}’ OFS=’\t’ predict.txt label.txt</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/13/%E7%AE%97%E6%B3%95-TextCNN/">算法-TextCNN</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-13T06:14:14.000Z" itemprop="datePublished">
    2022-07-13
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/Algorithm/">Algorithm</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <p>2012年在深度学习和卷积神经网络成为图像任务明星之后，2014年TextCNN诞生于世，成为了CNN在NLP文本分类任务上的经典之作。TextCNN提出的目的在于，希望将CNN在图像领域中所取得的成就复制于自然语言处理NLP任务中。</p>
<p>TextCNN利用卷积来提取文本n-gram特征，最大池化，全连接然后进行分类。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/13/%E8%AE%BA%E6%96%87-MarkBERT-Marking-Word-Boundaries-Improves-Chinese-BERT/">论文-MarkBERT: Marking Word Boundaries Improves Chinese BERT</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-12T16:56:17.000Z" itemprop="datePublished">
    2022-07-13
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/pretrained-model/">pretrained model</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/paper-reading/">paper reading</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <p>作者单位：腾讯AI实验室、复旦大学</p>
<p><strong>摘要</strong><br>&emsp;本文提出了一种基于词信息的中文BERT模型——MarkBERT模型。现有的基于单词的BERT模型以单词为基本单位，但由于BERT的词汇量限制，模型只涵盖高频单词，遇到词汇量不足(OOV)的单词时，模型退回到字符层面。与现有作品不同的是，MarkBERT将词汇表保持为汉字，并在相邻的单词之间插入边界标记。这样的设计使模型能够以相同的方式处理任何单词，无论它们是否是OOV单词。此外，我们的模型还有两个额外的好处:第一，它方便在标记的基础上增加词汇水平的学习目标，这是对传统的汉字和句子水平训练前任务的补充;其次，它可以通过将通用标记替换为特定于POS标记的标记，方便地合并更丰富的语义，如单词的POS标记。MarkBERT在MSRA数据集和OntoNotes数据集上的中文命名实体识别水平分别从95.4%和82.8%提高到96.5%和84.2%。与以往基于单词的BERT模型相比，MarkBERT模型在文本分类、关键字识别和语义相似度任务方面取得了更好的准确性。</p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/13/Pytorch-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">Pytorch-损失函数</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-12T16:55:27.000Z" itemprop="datePublished">
    2022-07-13
  </time>
  
  
</div>

    </header>
    <div>
      
        
      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2022/07/13/%E8%AE%BA%E6%96%87-What-Language-Model-Architecture-and-Pretraining-Objective-Work-Best-for-Zero-Shot-Generalization/">论文-What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2022-07-12T16:37:18.000Z" itemprop="datePublished">
    2022-07-13
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/zero-shot/">zero-shot</a> }
  </li>


  </ul>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/categories/paper-reading/">paper reading</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <p>作者单位：Hugging Face, Google, LightOn, Allen Institute for AI, LPENS École Normale Supérieure</p>
<p><strong>文章介绍</strong><br>这篇文章与 T5 在实验上的思路相似，通过大量对比设计，得到一个重磅结论：要是为了模型的 zero-shot 泛化能力，decoder 结构 + 语言模型任务最好；要是再 multitask finetuning，encoder-decoder 结构 + MLM 任务最好。除了找到最好的训练方式，作者通过大量的实验，还找到了最好的同时还能最节省成本的训练方式。训练计算量只需要九分之一！</p>

      
    </div>
</article>

    </li>
  
</ul>

  <section id="nav-wrapper">
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">next »</a>
    </nav>
  </section>


            <footer>
    <div>© 2022 - John Doe </div>
    <div>
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a target="_blank" rel="noopener" href="https://github.com/nameoverflow/hexo-theme-icalm">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>

<script src="/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>