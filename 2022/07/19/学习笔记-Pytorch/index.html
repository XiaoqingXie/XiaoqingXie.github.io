<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>学习笔记-Pytorch | Xiaoqing Xie</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url(/assets/myphoto.png)">
        </div>
    </section>
    <section class='menu'>
        <div>Xiaoqing Xie</div>
        
        <ul>
          
            <a href="/Resume/" class="Btn">
              <li>Resume</li>
            </a>  
          
            <a href="/" class="Btn">
              <li>Blogs</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
            <a href="/tags/" class="Btn">
              <li>Tags</li>
            </a>  
          
            <a href="/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/about/" class="Btn">
              <li>About</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a target="_blank" rel="noopener" href="https://github.com/XiaoqingXie">
                    <img src="/assets/github.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <div>
  <article class='ContentView'>
    <header class='PageTitle'>
        <h1>学习笔记-Pytorch</h1>
    </header>

    <section>
      <p><strong>Pytorch vs Tensorflow</strong><br>Pytorch:简洁、动态计算、visdom、部署不方便<br>Tensorflow: 接口复杂、静态图(TF2.0 Eager Execution已经引入动态图)、Tensorboard、部署方便(TF serving)</p>
<p><strong>Pytorch安装与环境搭建</strong><br>Ubuntu16.04–CUDA+cuDNN–Python3+pip3/Anaconda–Pytorch<br>硬件要求：GTX1080Ti+16G内存</p>
<p><strong>Pytorch的基本概念</strong></p>
<ol>
<li><p>Tensor 张量<br>&emsp;使用Tensor对样本进行描述<br>&emsp;使用Tensor对模型中的变量进行描述<br>&emsp;Tensor的创建<br>&emsp;Tensor(*size)    基础构造函数<br>&emsp;Tensor(data)    类似np.array<br>&emsp;标量是零维的张量，向量是一维的张量，矩阵是二维的张量。<br>&emsp;<strong>Tensor可以用来描述机器学习中的样本或者模型。</strong></p>
</li>
<li><p>Tensor创建编程实例</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">type</span>())</span><br></pre></td></tr></table></figure>
<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a = torch.Tensor(<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 指定tensor的形状</span></span><br><span class="line">b = torch.ones(<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 指定形状，初始化为全1的tensor</span></span><br><span class="line">c = torch.eye(<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 指定形状，初始化为对角线的tensor</span></span><br><span class="line">d = torch.zeros(<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 指定形状，初始化为全0的tensor</span></span><br><span class="line">a1 = torch.zeros_like(a) <span class="comment"># 以tensor a的形状，初始化一个全0的tensor</span></span><br><span class="line">a2 = torch.ones_like(a)</span><br><span class="line">a3 = torch.eye_like(a)</span><br><span class="line"><span class="comment"># 随机</span></span><br><span class="line">e = torch.rand(<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 指定tensor的形状,生成随机值的tensor</span></span><br><span class="line">f = torch.normal(mean=<span class="number">0.0</span>, std=torch.rand(<span class="number">5</span>))</span><br><span class="line">g = torch.Tensor(<span class="number">2</span>,<span class="number">2</span>).uniform(-<span class="number">1</span>,<span class="number">1</span>) <span class="comment">#先指定形状，再定义从-1到1之间的均匀分布tensor</span></span><br><span class="line"><span class="comment"># 序列</span></span><br><span class="line">h = torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1</span>) <span class="comment"># 从0-9的间隔1的tensor(long tensor)</span></span><br><span class="line">i = torch.linspace(<span class="number">2</span>, <span class="number">10</span>, <span class="number">3</span>) <span class="comment"># 等差tensor</span></span><br><span class="line">j = torch.randperm(<span class="number">10</span>) <span class="comment"># 从0-9打乱的tensor(long tensor)</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;numpy定义数据的实例<br>&emsp;&emsp;用法与Tensor类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>
<br>
3. Tensor的属性

<p>&emsp;&emsp;每一个Tensor有torch.dtype、torch.device、torch.layout三种属性。<br>&emsp;&emsp;torch.device标识了torch.Tensor对象再创建后所存储在的设备名称(cpu/gpu)。<br>&emsp;&emsp;torch.layout表示torch.Tensor内存布局对象。<br>&emsp;&emsp;例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tnesor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=torch.float32,device=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;稀疏的张量的定义<br>&emsp;&emsp;torch.sparse_coo_tensor<br>&emsp;&emsp;coo类型表示了非零元素的坐标形式<br>&emsp;&emsp;例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">dev = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">indices = torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]))  <span class="comment"># 坐标</span></span><br><span class="line">values = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])。<span class="comment"># 值</span></span><br><span class="line">x = torch.sparse_coo_tensor(indices, values, [<span class="number">4</span>,<span class="number">4</span>], dtype=torch.float32, device=dev) <span class="comment"># 对角线上有值的稀疏张量</span></span><br><span class="line">x = torch.sparse_coo_tensor(indices, values, [<span class="number">4</span>,<span class="number">4</span>], dtype=torch.float32, device=dev)。to_dense()  <span class="comment"># 转换成稠密张量</span></span><br></pre></td></tr></table></figure>
<br>
4. Tensor的算术运算

<p>&emsp;&emsp;<strong>四则运算</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加法</span></span><br><span class="line">c = a + b</span><br><span class="line">c = torch.add(a, b)</span><br><span class="line">a.add(b)</span><br><span class="line">a.add_(b) <span class="comment"># 会对a的值修改</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 减法</span></span><br><span class="line">c = a - b</span><br><span class="line">c = torch.sub(a, b)</span><br><span class="line">a.sub(b)</span><br><span class="line">a.sub_(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 乘法(哈达玛积, element wise, 对应元素相乘)</span></span><br><span class="line">c = a * b</span><br><span class="line">c = torch.mul(a, b)</span><br><span class="line">a.mul(b)</span><br><span class="line">a.mul_(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 除法</span></span><br><span class="line">c = a / b</span><br><span class="line">c = torch.div(a, b)</span><br><span class="line">a.div(b)</span><br><span class="line">a.div_(b)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>矩阵运算</strong><br>&emsp;&emsp;二维矩阵乘法运算操作包括torch.mm()、torch.matmul()、@</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">b = torch.ones(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">torch.mm(a, b)</span><br><span class="line">torch.matmul(a, b)</span><br><span class="line">a @ b</span><br><span class="line">a.matmul(b)</span><br><span class="line">a.mm(b)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;对于高位的Tensor(dim&gt;2)，定义其矩阵乘法仅在最后的两个维度上，要求前面的维度必须保持一致，就像矩阵的索引一样并且运算操作只有torch.matmul().</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = torch.ones(<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a.matmul(b))</span><br><span class="line"><span class="built_in">print</span>(torch.matmul(a,b))</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;幂运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">pow</span>(a, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">pow</span>(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(a**<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(a.pow_(<span class="number">2</span>)) <span class="comment"># 结果赋给a</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;e的n次方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.exp(a))</span><br><span class="line">b = a.exp_()</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;开方运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(a.sqrt())</span><br><span class="line"><span class="built_in">print</span>(a.sqrt_())</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;对数运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.log2(a))</span><br><span class="line"><span class="built_in">print</span>(torch.log10(a))</span><br><span class="line"><span class="built_in">print</span>(torch.log(a))</span><br><span class="line"><span class="built_in">print</span>(torch.log_(a))</span><br></pre></td></tr></table></figure>
<br>
5. Pytorch的广播机制

<p>&emsp;&emsp;<strong>广播机制：</strong>张量参数可以自动扩展为相同大小<br>&emsp;&emsp;广播机制需要满足两个条件：<br>&emsp;&emsp;&emsp;每个张量至少有一个维度；<br>&emsp;&emsp;&emsp;满足右对齐:对两个张量的维度从后往前（从右向左）处理，维度的大小必须<strong>要么相等，要么其中一个为1</strong>，或者其中一个张量后面不存在维度了；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.empty(<span class="number">5</span>,<span class="number">7</span>,<span class="number">3</span>)</span><br><span class="line">y = torch.empty(<span class="number">5</span>,<span class="number">7</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 形状相同，可以广播</span></span><br><span class="line"></span><br><span class="line">x=torch.empty((<span class="number">0</span>,))</span><br><span class="line">y=torch.empty(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 不能广播，因为两个张量都必须只有一个维度</span></span><br><span class="line"></span><br><span class="line">x=torch.empty(<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 可以广播</span></span><br><span class="line"><span class="comment"># 1st trailing dimension: both have size 1</span></span><br><span class="line"><span class="comment"># 2nd trailing dimension: y has size 1</span></span><br><span class="line"><span class="comment"># 3rd trailing dimension: x size == y size</span></span><br><span class="line"><span class="comment"># 4th trailing dimension: y dimension doesn&#x27;t exist</span></span><br><span class="line"></span><br><span class="line">x=torch.empty(<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># x和y不能广播，因为倒数第三个维度大小不同，且不为1</span></span><br></pre></td></tr></table></figure>



      

    </section>
    
      <section class='ArticleMeta'>
          <div>
            发布于&nbsp;
            <time datetime="2022-07-19T08:25:10.000Z" itemprop="datePublished">
              2022-07-19
            </time>
          </div>
          
      </section>
    
    
</article>

  
</div>

            <footer>
    <div>© 2022 - John Doe </div>
    <div>
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a target="_blank" rel="noopener" href="https://github.com/nameoverflow/hexo-theme-icalm">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>

<script src="/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>